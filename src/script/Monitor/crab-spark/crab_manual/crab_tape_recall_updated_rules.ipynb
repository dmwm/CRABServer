{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f91521a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://swan-prod-gpu-t4-5x-k4cbamaqo7dk-node-12:31134\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark_shell_swan</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3610a1b370>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "666f70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !hdfs dfs -stat /project/awg/cms/rucio/2023-07-24/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd6751a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/09 12:12:50 WARN ipc.Client: Exception encountered while connecting to the server \n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error\n",
      "\tat org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:376)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:622)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:413)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:822)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:818)\n",
      "\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat java.base/javax.security.auth.Subject.doAs(Subject.java:423)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:818)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:413)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1636)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1452)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1405)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)\n",
      "\tat com.sun.proxy.$Proxy12.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:964)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy13.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1731)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1725)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1722)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1737)\n",
      "\tat org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:115)\n",
      "\tat org.apache.hadoop.fs.Globber.doGlob(Globber.java:349)\n",
      "\tat org.apache.hadoop.fs.Globber.glob(Globber.java:202)\n",
      "\tat org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:2093)\n",
      "\tat org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:353)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:250)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:233)\n",
      "\tat org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:104)\n",
      "\tat org.apache.hadoop.fs.shell.Command.run(Command.java:177)\n",
      "\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:327)\n",
      "\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n",
      "\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)\n",
      "\tat org.apache.hadoop.fs.FsShell.main(FsShell.java:390)\n",
      "Found 10 items\n",
      "drwxrwxr-x+  - cmssqoop c3          0 2023-07-25 04:18 /project/awg/cms/rucio/2023-07-25/contents\n",
      "drwxrwxr-x+  - cmssqoop c3          0 2023-07-25 04:22 /project/awg/cms/rucio/2023-07-25/dataset_locks\n",
      "drwxrwxr-x+  - cmssqoop c3          0 2023-07-25 04:13 /project/awg/cms/rucio/2023-07-25/dids\n",
      "drwxrwxr-x+  - cmssqoop c3          0 2023-07-25 04:28 /project/awg/cms/rucio/2023-07-25/locks\n",
      "drwxrwxr-x+  - cmssqoop c3          0 2023-07-25 04:06 /project/awg/cms/rucio/2023-07-25/replicas\n",
      "drwxrwxr-x+  - cmssqoop c3          0 2023-07-25 04:46 /project/awg/cms/rucio/2023-07-25/requests_history\n",
      "drwxrwxr-x+  - cmssqoop c3          0 2023-07-25 04:53 /project/awg/cms/rucio/2023-07-25/rses\n",
      "drwxrwxr-x+  - cmssqoop c3          0 2023-07-25 04:33 /project/awg/cms/rucio/2023-07-25/rules\n",
      "drwxrwxr-x+  - cmssqoop c3          0 2023-07-25 04:38 /project/awg/cms/rucio/2023-07-25/rules_history\n",
      "drwxrwxr-x+  - cmssqoop c3          0 2023-07-25 04:50 /project/awg/cms/rucio/2023-07-25/subscriptions\n"
     ]
    }
   ],
   "source": [
    "# check available files\n",
    "!hdfs dfs -ls /project/awg/cms/rucio/2023-07-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800a2f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import click\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import time\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark import SparkContext, StorageLevel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, collect_list, concat_ws, greatest, lit, lower, when,\n",
    "    avg as _avg,\n",
    "    count as _count,\n",
    "    hex as _hex,\n",
    "    max as _max,\n",
    "    min as _min,\n",
    "    round as _round,\n",
    "    sum as _sum,\n",
    ")\n",
    "\n",
    "from pyspark.sql.types import (\n",
    "    LongType,\n",
    ")\n",
    "\n",
    "#from CMSSpark.src.python.CMSSpark import schemas as cms_schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597820f",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c100a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_date = str(datetime.now())[:10]\n",
    "# wa_date = \"2023-08-08\"\n",
    "\n",
    "HDFS_RUCIO_DATASET_LOCKS = f'/project/awg/cms/rucio/{wa_date}/dataset_locks/part*.avro'\n",
    "# HDFS_RUCIO_LOCKS =         f'/project/awg/cms/rucio/{wa_date}/locks'\n",
    "HDFS_RUCIO_RSES =          f'/project/awg/cms/rucio/{wa_date}/rses/part*.avro'\n",
    "HDFS_RUCIO_RULES =         f'/project/awg/cms/rucio/{wa_date}/rules'\n",
    "# HDFS_RUCIO_RULES_HISTORY = f'/project/awg/cms/rucio/{wa_date}/rules_history'\n",
    "# HDFS_RUCIO_REPLICAS =      f'/project/awg/cms/rucio/{wa_date}/replicas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe62d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "rucio_dataset_locks = spark.read.format('avro').load(HDFS_RUCIO_DATASET_LOCKS)\\\n",
    "    .withColumn('BYTES', col('BYTES').cast(LongType()))\\\n",
    "    .withColumn('RULE_ID', lower(_hex(col('RULE_ID'))))\\\n",
    "    .withColumn('RSE_ID', lower(_hex(col('RSE_ID')))).filter(f\"\"\"ACCOUNT IN ('crab_tape_recall')\"\"\").cache()\n",
    "rucio_dataset_locks.createOrReplaceTempView(\"dataset_locks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e4fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rucio_rses = spark.read.format('avro').load(HDFS_RUCIO_RSES)\\\n",
    "    .withColumn('ID', lower(_hex(col('ID'))))\n",
    "rucio_rses.createOrReplaceTempView(\"rses\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3893197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/09 12:37:11 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "rucio_rules = spark.read.format('avro').load(HDFS_RUCIO_RULES)\\\n",
    "    .withColumn('ID', lower(_hex(col('ID'))))\n",
    "rucio_rules.createOrReplaceTempView(\"rules\")\n",
    "#spark.sql(\"SELECT * FROM rules\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f2ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rucio_locks = spark.read.format('avro').load(HDFS_RUCIO_LOCKS)\\\n",
    "#     .withColumn('BYTES', col('BYTES').cast(LongType()))\\\n",
    "#     .withColumn('RULE_ID', lower(_hex(col('RULE_ID'))))\\\n",
    "#     .withColumn('RSE_ID', lower(_hex(col('RSE_ID'))))\n",
    "# rucio_locks.createOrReplaceTempView(\"locks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7771b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rucio_rules_history = spark.read.format('avro').load(HDFS_RUCIO_RULES_HISTORY)\\\n",
    "#     .withColumn('ID', lower(_hex(col('ID'))))\n",
    "#     #.persist(StorageLevel.DISK_ONLY)\n",
    "# rucio_rules_history.createOrReplaceTempView(\"rules_history\")\n",
    "# #spark.sql(\"SELECT * FROM rules_history\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274421b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rucio_replicas = spark.read.format('avro').load(HDFS_RUCIO_REPLICAS)\\\n",
    "#     .withColumn('RSE_ID', lower(_hex(col('RSE_ID'))))\n",
    "# rucio_replicas.createOrReplaceTempView(\"replicas\")\n",
    "# #spark.sql(\"SELECT * FROM replicas\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84635f",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be915ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rucio_dataset_locks.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8648794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rucio_dataset_locks.printSchema()\n",
    "# rucio_rses.printSchema()\n",
    "# rucio_rules.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aed55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rucio_dataset_locks = rucio_dataset_locks.select('')\n",
    "rucio_rses = rucio_rses.select('ID', 'RSE', 'RSE_TYPE').cache()\n",
    "rucio_rules = rucio_rules.select('ID', 'ACCOUNT', 'DID_TYPE', 'EXPIRES_AT').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "929705b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = rucio_dataset_locks.join(rucio_rses, rucio_rses[\"ID\"] == rucio_dataset_locks[\"RSE_ID\"])\\\n",
    "        .join(rucio_rules, rucio_rules[\"ID\"] == rucio_dataset_locks[\"RULE_ID\"]).drop('ID', 'RULE_ID', 'RSE_ID', 'ACCESSED_AT', 'ACCOUNT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49af7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91db6a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cbdf730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e734d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = result_df.toPandas().to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac8524e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17770"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d047c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(docs)):\n",
    "    docs[i]['SIZE_TiB'] = docs[i][\"BYTES\"]/1099511627776\n",
    "    del docs[i][\"BYTES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c052b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME = datetime.strptime(f\"\"\"{wa_date} 00:00:00\"\"\", \"%Y-%m-%d %H:%M:%S\").timestamp()*1000\n",
    "for i in range(len(docs)):\n",
    "    docs[i]['TIMESTAMP'] = TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "836a7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(docs)):\n",
    "    NAME_i = docs[i]['NAME']\n",
    "    split_NAME = NAME_i.split('#')[0]\n",
    "    docs[i]['NAME_'] = NAME_i.split('#')[0]\n",
    "    split_NAME = docs[i]['NAME_'].split('/')\n",
    "    if len(split_NAME) != 4:\n",
    "        print(\"YO HOO !!, something wrong.\", NAME_i)\n",
    "    docs[i]['PriDataset'] = split_NAME[1]\n",
    "    docs[i]['DataTier'] = split_NAME[-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51bf031e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'SCOPE': 'cms',\n",
       "  'NAME': '/ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8/RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v3/MINIAODSIM#c7b37e2d-77d8-40b9-b8c9-cdf7658406bd',\n",
       "  'STATE': 'O',\n",
       "  'LENGTH': '1',\n",
       "  'UPDATED_AT': 1689164433000,\n",
       "  'CREATED_AT': 1689096938000,\n",
       "  'RSE': 'T2_UK_SGrid_RALPP',\n",
       "  'RSE_TYPE': 'DISK',\n",
       "  'DID_TYPE': 'C',\n",
       "  'EXPIRES_AT': 1691719252000,\n",
       "  'SIZE_TiB': 0.0003293267427579849,\n",
       "  'TIMESTAMP': 1691532000000.0,\n",
       "  'NAME_': '/ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8/RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v3/MINIAODSIM',\n",
       "  'PriDataset': 'ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8',\n",
       "  'DataTier': 'MINIAODSIM'},\n",
       " {'SCOPE': 'cms',\n",
       "  'NAME': '/ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8/RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v3/MINIAODSIM#4e06c095-6b19-46a1-a6a6-321e6692a086',\n",
       "  'STATE': 'O',\n",
       "  'LENGTH': '1',\n",
       "  'UPDATED_AT': 1689164433000,\n",
       "  'CREATED_AT': 1689096938000,\n",
       "  'RSE': 'T2_UK_SGrid_RALPP',\n",
       "  'RSE_TYPE': 'DISK',\n",
       "  'DID_TYPE': 'C',\n",
       "  'EXPIRES_AT': 1691719252000,\n",
       "  'SIZE_TiB': 0.00011089865711255698,\n",
       "  'TIMESTAMP': 1691532000000.0,\n",
       "  'NAME_': '/ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8/RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v3/MINIAODSIM',\n",
       "  'PriDataset': 'ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8',\n",
       "  'DataTier': 'MINIAODSIM'},\n",
       " {'SCOPE': 'cms',\n",
       "  'NAME': '/ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8/RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v3/MINIAODSIM#1a79fa1f-9f97-4f0f-9716-523e29e57c32',\n",
       "  'STATE': 'O',\n",
       "  'LENGTH': '1',\n",
       "  'UPDATED_AT': 1689164433000,\n",
       "  'CREATED_AT': 1689096938000,\n",
       "  'RSE': 'T2_UK_SGrid_RALPP',\n",
       "  'RSE_TYPE': 'DISK',\n",
       "  'DID_TYPE': 'C',\n",
       "  'EXPIRES_AT': 1691719252000,\n",
       "  'SIZE_TiB': 0.001415386764165305,\n",
       "  'TIMESTAMP': 1691532000000.0,\n",
       "  'NAME_': '/ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8/RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v3/MINIAODSIM',\n",
       "  'PriDataset': 'ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8',\n",
       "  'DataTier': 'MINIAODSIM'},\n",
       " {'SCOPE': 'cms',\n",
       "  'NAME': '/ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8/RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v3/MINIAODSIM#18958704-f8f5-4ab4-8d26-0875a74714c4',\n",
       "  'STATE': 'O',\n",
       "  'LENGTH': '1',\n",
       "  'UPDATED_AT': 1689164433000,\n",
       "  'CREATED_AT': 1689096938000,\n",
       "  'RSE': 'T2_UK_SGrid_RALPP',\n",
       "  'RSE_TYPE': 'DISK',\n",
       "  'DID_TYPE': 'C',\n",
       "  'EXPIRES_AT': 1691719252000,\n",
       "  'SIZE_TiB': 0.0008716376141819637,\n",
       "  'TIMESTAMP': 1691532000000.0,\n",
       "  'NAME_': '/ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8/RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v3/MINIAODSIM',\n",
       "  'PriDataset': 'ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8',\n",
       "  'DataTier': 'MINIAODSIM'},\n",
       " {'SCOPE': 'cms',\n",
       "  'NAME': '/ParkingDoubleMuonLowMass1/Run2023C-PromptReco-v3/AOD#ef5c7b53-7002-4b16-bd94-c9e6cbd1ddc6',\n",
       "  'STATE': 'O',\n",
       "  'LENGTH': '1',\n",
       "  'UPDATED_AT': 1689903482000,\n",
       "  'CREATED_AT': 1689587082000,\n",
       "  'RSE': 'T2_BE_UCL',\n",
       "  'RSE_TYPE': 'DISK',\n",
       "  'DID_TYPE': 'C',\n",
       "  'EXPIRES_AT': 1692496353000,\n",
       "  'SIZE_TiB': 5.84150075155776e-06,\n",
       "  'TIMESTAMP': 1691532000000.0,\n",
       "  'NAME_': '/ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8/RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v3/MINIAODSIM',\n",
       "  'PriDataset': 'ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8',\n",
       "  'DataTier': 'MINIAODSIM'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c770068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'ZprimeToA0hToA0chichihbb_2HDM_MZp1700_MA0900_TuneCP2_13TeV_madgraph-pythia8',\n",
       " 'RunIIFall17MiniAODv2-PU2017_12Apr2018_94X_mc2017_realistic_v14-v3',\n",
       " 'MINIAODSIM#c7b37e2d-77d8-40b9-b8c9-cdf7658406bd']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_str = test_str.split('/')\n",
    "split_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a2868f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MINIAODSIM', 'c7b37e2d-77d8-40b9-b8c9-cdf7658406bd']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_str[3].split('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86f3a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d29e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_schema():\n",
    "    return {\n",
    "        \"settings\": {\"index\": {\"number_of_shards\": \"1\", \"number_of_replicas\": \"1\"}},\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                'SCOPE': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                'NAME': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                'STATE': {\"ignore_above\": 1024, \"type\": \"keyword\"},\n",
    "                'LENGTH': {\"ignore_above\": 1024, \"type\": \"keyword\"},\n",
    "                'SIZE_TiB': {\"type\": \"long\"},\n",
    "                'UPDATED_AT': {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                'CREATED_AT': {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                'RSE': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                'RSE_TYPE': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                'DID_TYPE': {\"ignore_above\": 1024, \"type\": \"keyword\"},\n",
    "                'EXPIRES_AT': {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                'TIMESTAMP': {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                'NAME_': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                'PriDataset': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                'DataTier': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b479eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _index_template = 'crab-tape-recall-rules-ekong'\n",
    "# client = osearch.get_es_client(\"es-cms1.cern.ch/es\", 'secret_opensearch.txt', get_index_schema())\n",
    "# # index_mod=\"\": 'test-foo', index_mod=\"Y\": 'test-foo-YYYY', index_mod=\"M\": 'test-foo-YYYY-MM', index_mod=\"D\": 'test-foo-YYYY-MM-DD',\n",
    "# idx = client.get_or_create_index(timestamp=time.time(), index_template=_index_template, index_mod=\"M\")\n",
    "# client.send(idx, docs, metadata=None, batch_size=10000, drop_nulls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af51d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from pyspark import SparkContext, StorageLevel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, collect_list, concat_ws, greatest, lit, lower, when,\n",
    "    avg as _avg,\n",
    "    count as _count,\n",
    "    hex as _hex,\n",
    "    max as _max,\n",
    "    min as _min,\n",
    "    round as _round,\n",
    "    sum as _sum,\n",
    ")\n",
    "\n",
    "from pyspark.sql.types import (\n",
    "    LongType,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import osearch\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e6ecf",
   "metadata": {},
   "source": [
    "## Multiple Day Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ece939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_upload(start_date, end_date):\n",
    "    # change to the date of collected data\n",
    "    start_date = start_date + timedelta(days=1)\n",
    "    end_date = end_date + timedelta(days=1)\n",
    "    \n",
    "    days = (end_date - start_date).days\n",
    "    for i in range(days):\n",
    "        TODAY = start_date + timedelta(days=i)\n",
    "        TODAY = str(TODAY)[:10]\n",
    "        \n",
    "        print(TODAY)\n",
    "        # Import data into database form\n",
    "\n",
    "        wa_date = TODAY\n",
    "        HDFS_RUCIO_DATASET_LOCKS = f'/project/awg/cms/rucio/{wa_date}/dataset_locks/part*.avro'\n",
    "        HDFS_RUCIO_RSES =          f'/project/awg/cms/rucio/{wa_date}/rses/part*.avro'\n",
    "        HDFS_RUCIO_RULES =         f'/project/awg/cms/rucio/{wa_date}/rules'\n",
    "\n",
    "        rucio_dataset_locks = spark.read.format('avro').load(HDFS_RUCIO_DATASET_LOCKS)\\\n",
    "            .withColumn('BYTES', col('BYTES').cast(LongType()))\\\n",
    "            .withColumn('RULE_ID', lower(_hex(col('RULE_ID'))))\\\n",
    "            .withColumn('RSE_ID', lower(_hex(col('RSE_ID')))).filter(f\"\"\"ACCOUNT IN ('crab_tape_recall')\"\"\").cache()\n",
    "        rucio_dataset_locks.createOrReplaceTempView(\"dataset_locks\")\n",
    "\n",
    "        rucio_rses = spark.read.format('avro').load(HDFS_RUCIO_RSES)\\\n",
    "            .withColumn('ID', lower(_hex(col('ID'))))\n",
    "        rucio_rses.createOrReplaceTempView(\"rses\")\n",
    "\n",
    "        rucio_rules = spark.read.format('avro').load(HDFS_RUCIO_RULES)\\\n",
    "            .withColumn('ID', lower(_hex(col('ID'))))\n",
    "        rucio_rules.createOrReplaceTempView(\"rules\")\n",
    "\n",
    "        # filter and query\n",
    "\n",
    "        rucio_rses = rucio_rses.select('ID', 'RSE', 'RSE_TYPE').cache()\n",
    "        rucio_rules = rucio_rules.select('ID', 'ACCOUNT', 'DID_TYPE', 'EXPIRES_AT').cache()\n",
    "\n",
    "        result_df = rucio_dataset_locks.join(rucio_rses, rucio_rses[\"ID\"] == rucio_dataset_locks[\"RSE_ID\"])\\\n",
    "                .join(rucio_rules, rucio_rules[\"ID\"] == rucio_dataset_locks[\"RULE_ID\"]).drop('ID', 'RULE_ID', 'RSE_ID', 'ACCESSED_AT', 'ACCOUNT')\n",
    "\n",
    "        # Convert database to dictionary\n",
    "\n",
    "        docs = result_df.toPandas().to_dict('records')\n",
    "            \n",
    "        # Add TIMESTAMP column and convert TiB\n",
    "        TIME = datetime.strptime(f\"\"\"{wa_date} 00:00:00\"\"\", \"%Y-%m-%d %H:%M:%S\").timestamp()*1000\n",
    "        for i in range(len(docs)):\n",
    "            docs[i]['TIMESTAMP'] = TIME\n",
    "            docs[i]['SIZE_TiB'] = docs[i][\"BYTES\"]/1099511627776\n",
    "            del docs[i][\"BYTES\"]\n",
    "            \n",
    "            # break down the name\n",
    "            NAME_i = docs[i]['NAME']\n",
    "            split_NAME = NAME_i.split('#')[0]\n",
    "            docs[i]['NAME_'] = NAME_i.split('#')[0]\n",
    "            split_NAME = docs[i]['NAME_'].split('/')\n",
    "            if len(split_NAME) != 4:\n",
    "                print(\"YO HOO !!, something wrong.\", NAME_i)\n",
    "            docs[i]['PriDataset'] = split_NAME[1]\n",
    "            docs[i]['DataTier'] = split_NAME[-1]\n",
    "\n",
    "        # Define type of each schema\n",
    "\n",
    "        def get_index_schema():\n",
    "            return {\n",
    "                \"settings\": {\"index\": {\"number_of_shards\": \"1\", \"number_of_replicas\": \"1\"}},\n",
    "                \"mappings\": {\n",
    "                    \"properties\": {\n",
    "                        'SCOPE': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                        'NAME': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                        'STATE': {\"ignore_above\": 1024, \"type\": \"keyword\"},\n",
    "                        'LENGTH': {\"ignore_above\": 1024, \"type\": \"keyword\"},\n",
    "                        'BYTES': {\"type\": \"long\"},\n",
    "                        'UPDATED_AT': {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                        'CREATED_AT': {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                        'RSE': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                        'RSE_TYPE': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                        'DID_TYPE': {\"ignore_above\": 1024, \"type\": \"keyword\"},\n",
    "                        'EXPIRES_AT': {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                        'TIMESTAMP': {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                        'NAME_': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                        'PriDataset': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                        'DataTier': {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "        # Send data to Opensearch\n",
    "\n",
    "        _index_template = 'crab-tape-recall-rules-ekong'\n",
    "        client = osearch.get_es_client(\"es-cms1.cern.ch/es\", 'secret_opensearch.txt', get_index_schema())\n",
    "        idx = client.get_or_create_index(timestamp=time.time(), index_template=_index_template, index_mod=\"M\")\n",
    "        no_of_fail_saved = client.send(idx, docs, metadata=None, batch_size=10000, drop_nulls=False)\n",
    "\n",
    "        print(\"========================================================================\", \"FINISHED : \", len(docs), \"ROWS ARE SENT\", no_of_fail_saved, \"ROWS ARE FAILED\", \"========================================================================\", sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4567c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'es-cms1.cern.ch'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'es-cms1.cern.ch'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'es-cms1.cern.ch'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'es-cms1.cern.ch'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "FINISHED : \n",
      "40190\n",
      "ROWS ARE SENT\n",
      "0\n",
      "ROWS ARE FAILED\n",
      "========================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_103swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'es-cms1.cern.ch'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# upload the data of start_date day to end_date-1d\n",
    "start_date = datetime(2023, 7, 23)\n",
    "end_date = datetime(2023, 7, 24)\n",
    "\n",
    "multi_upload(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e9d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e681c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": [
    {
     "name": "spark.jars.packages",
     "value": "org.apache.spark:spark-avro_2.12:3.3.1"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
